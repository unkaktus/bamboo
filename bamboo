#!/usr/bin/env python

from tabulate import tabulate
import subprocess
import os
import sys
import numpy as np
import pandas
import glob
import subprocess
import click
from astropy import units as u, constants as const

parfile_dir = ""

@click.group()
@click.option('--root', default='.', help='Location of the runs')
def cli(root):
    global parfile_dir
    parfile_dir = root
    pass

def is_bam_run(run_dir) -> bool:
    system_log_filename = os.path.join(run_dir, 'system.log')
    return os.path.isfile(system_log_filename)

def runstats(run_dir):
    system_log_filename = os.path.join(run_dir, 'system.log')

    with open(system_log_filename) as f:
        lines = f.readlines()
        last_line = lines[-1].split()
        time, speed = last_line[0], last_line[3]
        return time, speed

def spanner_list():
    spanner_output = subprocess.check_output(['spanner', 'list'])

    jobs = {}
    for line_b in spanner_output.splitlines()[2:]:
        line = line_b.decode('utf-8')
        if line.startswith("├") or line.startswith("╰"):
            continue
        ls = line.split()
        name, status, progress, progress_time = ls[1], ls[3], ls[8], ls[9]
        jobs[name] = (status, progress, progress_time)
    return jobs

def number_of_lines(filename):
    with open(filename, "rb") as f:
        num_lines = sum(1 for _ in f)
        return num_lines

def merger_status(run_dir):
    moving_puncture_filename_glob =  os.path.join(run_dir, 'moving_puncture_distance.lxyz*')
    mpd_filename = glob.glob(moving_puncture_filename_glob)[0]
    n_lines = number_of_lines(mpd_filename)
    mpd = np.loadtxt(mpd_filename, skiprows=n_lines-2)
    distance = mpd[-1,6]

    if distance > 1e-2:
        return "inspiral"
    if distance < 1e-2 and distance > 1e-12:
        return "merger"
    if distance < 1e-12:
        return "postmerger"

def count_lines(filename):
    with open(filename, "rbU") as f:
        num_lines = sum(1 for _ in f)
        return num_lines

def merger_time(run_dir):
    moving_puncture_filename_glob =  os.path.join(run_dir, 'moving_puncture_distance.lxyz*')
    mpd_filename = glob.glob(moving_puncture_filename_glob)[0]
    skiprows = 1
    mpd = pandas.read_csv(mpd_filename, skiprows=skiprows, header=None, delimiter='\s+', dtype=float).values
    d = mpd[:,6]

    threshold = 30
    d[d>threshold] = threshold

    time = mpd[:,8]
    gg = np.gradient(np.gradient(d))
    a = np.argmin(gg)
    merger_time = time[a]

    print(f'{run_dir} merger_d: {d[a]}')

    distance = d[-1]
    status = ""
    if distance > 1e-2:
        status = "inspiral"
    if distance < 1e-2 and distance > 1e-12:
        status = "merger"
    if distance < 1e-12:
        status = "postmerger"
    if status != "postmerger":
        merger_time = 0.0
    return merger_time, status


class GU():
    def __init__(self, v):
        self.v = v*u.Msun
        self.M = self._to(u.g)
        self.L = self._to(u.cm)
        self.T = self._to(u.s)
        self.Density = self.MLT(1, -3, 0)
        self.Energy = self.MLT(1, 2, -2)
        self.MagneticFluxDensity = self.MLT(1/2, -1/2, -1)
        self.Luminosity = self.Energy/self.T
    def _to(self, unit):
        if unit.is_equivalent(u.Msun):
            return self.v.to(unit)
        if unit.is_equivalent(u.cm):
            return (self.v*const.G/const.c**2).to(unit)
        if unit.is_equivalent(u.s):
            return (self.v*const.G/const.c**3).to(unit)
    def MLT(self, m, l, t):
        return self.M**m * self.L**l * self.T**t

@click.command()
@click.argument('run_name')
@click.option('--processors', default=0, help='Number of processors to use')
def pack(run_name, processors):
    run_dir_path = os.path.join(os.path.abspath(parfile_dir), run_name)
    pack_path = os.path.join(os.path.abspath(parfile_dir), f'{run_name}.squashfs')
    command = ["mksquashfs", run_dir_path, pack_path,
        "-no-xattrs",
        "-e", "checkpoint.*", "-wildcards",
        "-comp", "gzip", "-noD",
        "-Xcompression-level", "2",
        ]
    processors = 128
    if processors > 0:
        command.append(["-processors", f"{processors}"])

    subprocess.run(command,
        stdout=sys.stdout,
        stderr=sys.stdout,
    )
cli.add_command(pack)


@click.command()
def list():
    table_header = ["Name", "Time", "Speed", "Done in", "Merger Status", "Status", "Progress"]
    jobs = spanner_list()
    run_dirs = next(os.walk(parfile_dir))[1]

    table = []
    run_notes = {}

    for run_dir in run_dirs:
        try:
            run_dir_path = os.path.join(os.path.abspath(parfile_dir), run_dir)
            if not is_bam_run(run_dir_path):
              continue
            time, speed_str = runstats(run_dir_path)
            speed = float(speed_str.removesuffix('M/h')) * GU(1).T.to('ms') / u.h
            status, progress, progress_time = ["-", "-", "-"]
            if run_dir in jobs:
                job = jobs[run_dir]
                (status, progress, progress_time) = job
            m_time, m_status = merger_time(run_dir_path)
            time_ms = (float(time[:-1]) - m_time) * GU(1).T.to('ms').value
            time_str = f'{time} ({time_ms:.1f}ms)'
            if m_status == "postmerger":
                time_str = f'{time} ({time_ms:.1f}msam)'
                done_in = ((32 * u.ms - time_ms*u.ms) / speed).to('d')
                done_in_str = f'{done_in.value:.2f}d'
            else:
                done_in_str = "-"
            table.append([run_dir, time_str, speed_str, done_in_str, f'{m_status} ({m_time})', status, f'{progress} {progress_time}'])
        except Exception as e:
            print(e)
            table.append([run_dir, "-", "-", "-", "-", "-", "-", "-"])

    print(tabulate(table, headers=table_header, tablefmt='rounded_outline'))

cli.add_command(list)

if __name__ == '__main__':
    cli()
